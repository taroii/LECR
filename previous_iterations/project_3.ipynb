{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TITLE\n",
    "\n",
    "In this approach, I will concatenate the correlations data with the content data to train a multilabel classification model. With that model, I will predict the labels for all of the topics in the topics dataset, as I will have first formatted the topics dataset to match the format of the content dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic_id</th>\n",
       "      <th>content_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>t_00004da3a1b2</td>\n",
       "      <td>c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>t_00068291e9a4</td>\n",
       "      <td>c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t_00069b63a70a</td>\n",
       "      <td>c_11a1dc0bfb99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>t_0006d41a73a8</td>\n",
       "      <td>c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>t_0008768bdee6</td>\n",
       "      <td>c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic_id                                        content_ids\n",
       "0  t_00004da3a1b2  c_1108dd0c7a5d c_376c5a8eb028 c_5bc0e1e2cba0 c...\n",
       "1  t_00068291e9a4  c_639ea2ef9c95 c_89ce9367be10 c_ac1672cdcd2c c...\n",
       "2  t_00069b63a70a                                     c_11a1dc0bfb99\n",
       "3  t_0006d41a73a8  c_0c6473c3480d c_1c57a1316568 c_5e375cf14c47 c...\n",
       "4  t_0008768bdee6       c_34e1424229b4 c_7d1a964d66d5 c_aab93ee667f4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "\n",
    "topics = pd.read_csv(\"topics.csv\")\n",
    "topics.head()\n",
    "content = pd.read_csv('content.csv')\n",
    "content.head()\n",
    "correlations = pd.read_csv('correlations.csv')\n",
    "correlations.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>kind</th>\n",
       "      <th>text</th>\n",
       "      <th>language</th>\n",
       "      <th>copyright_holder</th>\n",
       "      <th>license</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c_00002381196d</td>\n",
       "      <td>Sumar números de varios dígitos: 48,029+233,930</td>\n",
       "      <td>Suma 48,029+233,930 mediante el algoritmo está...</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c_000087304a9e</td>\n",
       "      <td>Trovare i fattori di un numero</td>\n",
       "      <td>Sal trova i fattori di 120.\\n\\n</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>it</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c_0000ad142ddb</td>\n",
       "      <td>Sumar curvas de demanda</td>\n",
       "      <td>Cómo añadir curvas de demanda\\n\\n</td>\n",
       "      <td>video</td>\n",
       "      <td>NaN</td>\n",
       "      <td>es</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c_0000c03adc8d</td>\n",
       "      <td>Nado de aproximação</td>\n",
       "      <td>Neste vídeo você vai aprender o nado de aproxi...</td>\n",
       "      <td>document</td>\n",
       "      <td>\\nNado de aproximação\\nSaber nadar nas ondas ...</td>\n",
       "      <td>pt</td>\n",
       "      <td>Sikana Education</td>\n",
       "      <td>CC BY-NC-ND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c_00016694ea2a</td>\n",
       "      <td>geometry-m3-topic-a-overview.pdf</td>\n",
       "      <td>geometry-m3-topic-a-overview.pdf</td>\n",
       "      <td>document</td>\n",
       "      <td>Estándares Comunes del Estado de Nueva York\\n\\...</td>\n",
       "      <td>es</td>\n",
       "      <td>Engage NY</td>\n",
       "      <td>CC BY-NC-SA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                             title  \\\n",
       "0  c_00002381196d  Sumar números de varios dígitos: 48,029+233,930    \n",
       "1  c_000087304a9e                    Trovare i fattori di un numero   \n",
       "2  c_0000ad142ddb                           Sumar curvas de demanda   \n",
       "3  c_0000c03adc8d                               Nado de aproximação   \n",
       "4  c_00016694ea2a                  geometry-m3-topic-a-overview.pdf   \n",
       "\n",
       "                                         description      kind  \\\n",
       "0  Suma 48,029+233,930 mediante el algoritmo está...     video   \n",
       "1                    Sal trova i fattori di 120.\\n\\n     video   \n",
       "2                  Cómo añadir curvas de demanda\\n\\n     video   \n",
       "3  Neste vídeo você vai aprender o nado de aproxi...  document   \n",
       "4                   geometry-m3-topic-a-overview.pdf  document   \n",
       "\n",
       "                                                text language  \\\n",
       "0                                                NaN       es   \n",
       "1                                                NaN       it   \n",
       "2                                                NaN       es   \n",
       "3  \\nNado de aproximação\\nSaber nadar nas ondas ...       pt   \n",
       "4  Estándares Comunes del Estado de Nueva York\\n\\...       es   \n",
       "\n",
       "   copyright_holder      license  \n",
       "0               NaN          NaN  \n",
       "1               NaN          NaN  \n",
       "2               NaN          NaN  \n",
       "3  Sikana Education  CC BY-NC-ND  \n",
       "4         Engage NY  CC BY-NC-SA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_UNIQUE_CONTENT = len(content.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bg' 'en' 'pt' 'gu' 'my' 'zh' 'ar' 'te' 'es' 'fr' 'sw' 'mr' 'hi' 'bn'\n",
      " 'fil' 'ru' 'it' 'or' 'pnb' 'km' 'as' 'kn' 'ur' 'pl' 'ta' 'swa' 'tr' 'mul']\n",
      "['es' 'it' 'pt' 'en' 'mr' 'bg' 'gu' 'sw' 'hi' 'ar' 'bn' 'as' 'zh' 'fr'\n",
      " 'km' 'pl' 'ta' 'fil' 'or' 'ru' 'kn' 'swa' 'my' 'pnb' 'tr' 'te' 'ur']\n"
     ]
    }
   ],
   "source": [
    "print(topics.language.unique())\n",
    "print(content.language.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(correlations, topics, content):\n",
    "    #Explode correlations rows\n",
    "    correlations[\"content_ids\"] = correlations[\"content_ids\"].str.split()\n",
    "    correlations = correlations.explode(\"content_ids\")\n",
    "\n",
    "    #Format content/topics to match (id/features)\n",
    "    content[\"text\"] = content[\"text\"].fillna('')\n",
    "    content = content.dropna()\n",
    "    content_combined = content[\"language\"] + \" \" + content[\"title\"] + \" \" + content[\"description\"] + \" \" + content[\"text\"]\n",
    "    content_combined = pd.DataFrame({\"features\":content_combined, \"content_id\":content[\"id\"]})\n",
    "\n",
    "    topics[\"description\"] = topics[\"description\"].fillna('')\n",
    "    topics = topics.dropna()\n",
    "    topics_combined = topics[\"language\"] + \" \" + topics[\"channel\"] + ' ' + topics[\"title\"] + \" \" + topics[\"description\"]\n",
    "    topics_combined = pd.DataFrame({\"id\":topics[\"id\"], \"features\":topics_combined})\n",
    "\n",
    "    #Combine to create new dataset\n",
    "    corr_topics = correlations.merge(topics_combined, how=\"inner\", left_on=\"topic_id\", right_on=\"id\")\n",
    "    #corr_topic_ids = corr_topics[['topic_id']]\n",
    "    corr_topics = pd.DataFrame({'features':corr_topics['features'], 'content_id':corr_topics[\"content_ids\"]})\n",
    "    out = pd.concat([corr_topics, content_combined])\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(321513, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_ds = combine(correlations, topics, content)\n",
    "np.shape(combined_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>content_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bg 000cf7 Откриването на резисторите Изследван...</td>\n",
       "      <td>c_1108dd0c7a5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bg 000cf7 Откриването на резисторите Изследван...</td>\n",
       "      <td>c_376c5a8eb028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bg 000cf7 Откриването на резисторите Изследван...</td>\n",
       "      <td>c_5bc0e1e2cba0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bg 000cf7 Откриването на резисторите Изследван...</td>\n",
       "      <td>c_76231f9d0b5e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pt 8e286a Entradas e saídas de uma função Ente...</td>\n",
       "      <td>c_639ea2ef9c95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features      content_id\n",
       "0  bg 000cf7 Откриването на резисторите Изследван...  c_1108dd0c7a5d\n",
       "1  bg 000cf7 Откриването на резисторите Изследван...  c_376c5a8eb028\n",
       "2  bg 000cf7 Откриването на резисторите Изследван...  c_5bc0e1e2cba0\n",
       "3  bg 000cf7 Откриването на резисторите Изследван...  c_76231f9d0b5e\n",
       "4  pt 8e286a Entradas e saídas de uma função Ente...  c_639ea2ef9c95"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>content_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bg 000cf7 Откриването на резисторите Изследван...</td>\n",
       "      <td>c_1108dd0c7a5d</td>\n",
       "      <td>10215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bg 000cf7 Откриването на резисторите Изследван...</td>\n",
       "      <td>c_376c5a8eb028</td>\n",
       "      <td>33409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bg 000cf7 Откриването на резисторите Изследван...</td>\n",
       "      <td>c_5bc0e1e2cba0</td>\n",
       "      <td>55276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bg 000cf7 Откриването на резисторите Изследван...</td>\n",
       "      <td>c_76231f9d0b5e</td>\n",
       "      <td>70947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pt 8e286a Entradas e saídas de uma função Ente...</td>\n",
       "      <td>c_639ea2ef9c95</td>\n",
       "      <td>59974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features      content_id     id\n",
       "0  bg 000cf7 Откриването на резисторите Изследван...  c_1108dd0c7a5d  10215\n",
       "1  bg 000cf7 Откриването на резисторите Изследван...  c_376c5a8eb028  33409\n",
       "2  bg 000cf7 Откриването на резисторите Изследван...  c_5bc0e1e2cba0  55276\n",
       "3  bg 000cf7 Откриването на резисторите Изследван...  c_76231f9d0b5e  70947\n",
       "4  pt 8e286a Entradas e saídas de uma função Ente...  c_639ea2ef9c95  59974"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_ds[\"content_id\"] = combined_ds[\"content_id\"].astype('category')\n",
    "combined_ds[\"id\"] = combined_ds[\"content_id\"].cat.codes\n",
    "combined_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_to_category = pd.Series(combined_ds.content_id.values, index=combined_ds.id).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bg 000cf7 Откриването на резисторите Изследван...</td>\n",
       "      <td>10215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bg 000cf7 Откриването на резисторите Изследван...</td>\n",
       "      <td>33409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bg 000cf7 Откриването на резисторите Изследван...</td>\n",
       "      <td>55276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bg 000cf7 Откриването на резисторите Изследван...</td>\n",
       "      <td>70947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pt 8e286a Entradas e saídas de uma função Ente...</td>\n",
       "      <td>59974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features     id\n",
       "0  bg 000cf7 Откриването на резисторите Изследван...  10215\n",
       "1  bg 000cf7 Откриването на резисторите Изследван...  33409\n",
       "2  bg 000cf7 Откриването на резисторите Изследван...  55276\n",
       "3  bg 000cf7 Откриването на резисторите Изследван...  70947\n",
       "4  pt 8e286a Entradas e saídas de uma função Ente...  59974"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_ds = combined_ds.drop(\"content_id\", axis=1)\n",
    "combined_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ds, test_ds = train_test_split(\n",
    "    combined_ds,\n",
    "    train_size=0.8,\n",
    "    test_size=0.2,\n",
    "    random_state=10,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(257210, 2)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91633</th>\n",
       "      <td>es 36a98b Seleccionar procedimientos para calc...</td>\n",
       "      <td>54244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51586</th>\n",
       "      <td>es Lección 1 Determinando las consecuencias en...</td>\n",
       "      <td>51581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100915</th>\n",
       "      <td>fr c152d6 Dérivée d'un produit, d'un quotient ...</td>\n",
       "      <td>95527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129902</th>\n",
       "      <td>en ebc86c 2C: Understanding Protein Conformation</td>\n",
       "      <td>6342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176813</th>\n",
       "      <td>es 36a98b Ecuación estándar de un círculo Apre...</td>\n",
       "      <td>117491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 features      id\n",
       "91633   es 36a98b Seleccionar procedimientos para calc...   54244\n",
       "51586   es Lección 1 Determinando las consecuencias en...   51581\n",
       "100915  fr c152d6 Dérivée d'un produit, d'un quotient ...   95527\n",
       "129902  en ebc86c 2C: Understanding Protein Conformation     6342\n",
       "176813  es 36a98b Ecuación estándar de un círculo Apre...  117491"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64303, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create custom standardization function to deal with punctuations, lowering the text, and removing stopwords\n",
    "#dictionary of languages found in our data\n",
    "lang_dict = {\n",
    "    \"en\":\"english\",\n",
    "    \"es\":\"spanish\",\n",
    "    \"it\":\"italian\",\n",
    "    'pt':\"portuguese\",\n",
    "    'mr':'marathi',\n",
    "    'bg':'bulgarian',\n",
    "    'gu':'gujarati',\n",
    "    'sw':'swahili',\n",
    "    'hi':'hindi',\n",
    "    'ar':'arabic',\n",
    "    'bn':'bengali',\n",
    "    'as':'assamese',\n",
    "    'zh':'chinese',\n",
    "    'fr':'french',\n",
    "    'km':'khmer',\n",
    "    'pl':'polish',\n",
    "    'ta':'tamil',\n",
    "    'or':'oriya',\n",
    "    'ru':'russian',\n",
    "    'kn':'kannada',\n",
    "    'swa':'swahili',\n",
    "    'my':'burmese',\n",
    "    'pnb':'punjabi',\n",
    "    'fil':'filipino',\n",
    "    'tr':'turkish',\n",
    "    'te':'telugu',\n",
    "    'ur':'urdu',\n",
    "    'fi':'finnish',\n",
    "    'pn':'unknown'}\n",
    "\n",
    "#list of languages supported by the natural language tool kit (NLTK) module.\n",
    "supported_languages = stopwords.fileids()\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    lang_code = text[0:2]\n",
    "    if lang_dict[lang_code] in supported_languages:\n",
    "        for word in stopwords.words(lang_dict[lang_code]):\n",
    "            text = text.replace(' ' + word + ' ', ' ')\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds['features'] = train_ds.features.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91633</th>\n",
       "      <td>es 36a98b Seleccionar procedimientos calcular ...</td>\n",
       "      <td>54244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51586</th>\n",
       "      <td>es Lección 1 Determinando consecuencias cascad...</td>\n",
       "      <td>51581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100915</th>\n",
       "      <td>fr c152d6 Dérivée d'un produit, d'un quotient ...</td>\n",
       "      <td>95527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129902</th>\n",
       "      <td>en ebc86c 2C: Understanding Protein Conformation</td>\n",
       "      <td>6342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176813</th>\n",
       "      <td>es 36a98b Ecuación estándar círculo Aprende ac...</td>\n",
       "      <td>117491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 features      id\n",
       "91633   es 36a98b Seleccionar procedimientos calcular ...   54244\n",
       "51586   es Lección 1 Determinando consecuencias cascad...   51581\n",
       "100915  fr c152d6 Dérivée d'un produit, d'un quotient ...   95527\n",
       "129902  en ebc86c 2C: Understanding Protein Conformation     6342\n",
       "176813  es 36a98b Ecuación estándar círculo Aprende ac...  117491"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds['features'] = test_ds.features.apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76452</th>\n",
       "      <td>zh f83dcf 长方形、正方形面积的计算 计算长方形和正方形的面积</td>\n",
       "      <td>136066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253012</th>\n",
       "      <td>en 0ec697 Defining convergent divergent infini...</td>\n",
       "      <td>112866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98506</th>\n",
       "      <td>es f65044 1 Tomamos decisiones familia cuidar ...</td>\n",
       "      <td>117667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205777</th>\n",
       "      <td>en abd7dc 9: Ontologies Natural Languages</td>\n",
       "      <td>27546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182637</th>\n",
       "      <td>en 0ec697 Appropriate units Learn work units a...</td>\n",
       "      <td>72297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 features      id\n",
       "76452                 zh f83dcf 长方形、正方形面积的计算 计算长方形和正方形的面积  136066\n",
       "253012  en 0ec697 Defining convergent divergent infini...  112866\n",
       "98506   es f65044 1 Tomamos decisiones familia cuidar ...  117667\n",
       "205777         en abd7dc 9: Ontologies Natural Languages    27546\n",
       "182637  en 0ec697 Appropriate units Learn work units a...   72297"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_standardize(text):    \n",
    "\n",
    "    text = tf.strings.lower(text, encoding='utf-8') #lowercase\n",
    "    text = tf.strings.regex_replace(text, f\"([{string.punctuation}])\", r\"\") #remove punctuation\n",
    "    text = tf.strings.regex_replace(text, '\\n', \"\") #remove newlines\n",
    "    text = tf.strings.regex_replace(text, ' +', \" \") #remove 2+ whitespaces\n",
    "    text = tf.strings.strip(text) #remove leading and tailing whitespaces\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 60000 #INCREASE WHEN TRAINING FR!\n",
    "MAX_LEN = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    "    standardize = my_standardize,\n",
    "    split = \"whitespace\",\n",
    "    max_tokens = VOCAB_SIZE + 2,\n",
    "    output_mode = 'int',\n",
    "    output_sequence_length = MAX_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adapt text vectorization layer\n",
    "vectorize_layer.adapt(train_ds.features)\n",
    "vocab = vectorize_layer.get_vocabulary()  # To get words back from token indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build datapipeline\n",
    "train_features_raw = tf.data.Dataset.from_tensor_slices(\n",
    "    tf.cast(train_ds.features, tf.string)\n",
    ")\n",
    "\n",
    "train_labels = tf.data.Dataset.from_tensor_slices(\n",
    "    tf.cast(train_ds.id, tf.int32)\n",
    ")\n",
    "\n",
    "test_features_raw = tf.data.Dataset.from_tensor_slices(\n",
    "    tf.cast(test_ds.features, tf.string)\n",
    ")\n",
    "\n",
    "test_labels = tf.data.Dataset.from_tensor_slices(\n",
    "    tf.cast(test_ds.id, tf.int32)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_input(sample):\n",
    "    text = sample\n",
    "    text = tf.expand_dims(text, -1)  \n",
    "    return tf.squeeze(vectorize_layer(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert text input to vectorized format\n",
    "train_features = train_features_raw.map(convert_text_input, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_features = test_features_raw.map(convert_text_input, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[   77   372 12145 12218  1664  8165  4556  5018     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0], shape=(50,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[   77   283    13 28317  7306 30159  1078     1     1 10505 26292  3694\n",
      "   101   116    54    40    44    14    17     1  4802  2422  7800  8178\n",
      "  8624  3694   926     1    19     7    36    65   334    48    58    47\n",
      "    59  1308  1323   438     7  1082    21     2  1301   231   307     5\n",
      "   985  1272], shape=(50,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[  256   473  9380  1859  7770  1859  2607  1637  2171 19213     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0], shape=(50,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for element in train_features.take(3):\n",
    "    print(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_ds = tf.data.Dataset.zip((\n",
    "    train_features,\n",
    "    train_labels\n",
    "))\n",
    "\n",
    "test_tf_ds = tf.data.Dataset.zip((\n",
    "    test_features,\n",
    "    test_labels\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input (features) X.shape:  (50,)\n",
      "output (label) y.shape:  ()\n",
      "input (features) X:  tf.Tensor(\n",
      "[   77   372 12145 12218  1664  8165  4556  5018     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0], shape=(50,), dtype=int64)\n",
      "output (label) y:  tf.Tensor(54244, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for X,y in train_tf_ds.take(1):\n",
    "  print(\"input (features) X.shape: \", X.shape)\n",
    "  print(\"output (label) y.shape: \", y.shape)\n",
    "  print(\"input (features) X: \", X)\n",
    "  print(\"output (label) y: \", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_tf_ds = train_tf_ds.batch(batch_size = BATCH_SIZE, drop_remainder=True)\\\n",
    "    .cache()\\\n",
    "        .prefetch(AUTOTUNE)\n",
    "\n",
    "test_tf_ds = test_tf_ds.batch(batch_size = BATCH_SIZE, drop_remainder=True)\\\n",
    "    .cache()\\\n",
    "        .prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=<unknown>, dtype=tf.int64, name=None),\n",
       " TensorSpec(shape=(64,), dtype=tf.int32, name=None))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tf_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    input_tokens = Input(shape=(MAX_LEN, ), dtype=tf.int32)\n",
    "    embedding_layer = Embedding(VOCAB_SIZE, 256)\n",
    "    GAP_layer = GlobalAveragePooling1D()\n",
    "    flatten_layer = Flatten()\n",
    "    \n",
    "    x = embedding_layer(input_tokens)\n",
    "    x = GAP_layer(x)\n",
    "    x = flatten_layer(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    output = Dense(1, activation='sigmoid')(x) #Show 10 best contents for each topics (then we will filter further)\n",
    "\n",
    "    model = Model(inputs = input_tokens, outputs = output)\n",
    "\n",
    "    LOSS_FUN = 'binary_crossentropy'\n",
    "    OPTIMIZER = 'adam'\n",
    "    METRIC = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "    model.compile(optimizer = OPTIMIZER, loss = LOSS_FUN, metrics = METRIC)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154047\n",
      "257210\n"
     ]
    }
   ],
   "source": [
    "print(NUM_UNIQUE_CONTENT)\n",
    "print(len(train_ds.features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 50)]              0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 50, 256)           15360000  \n",
      "                                                                 \n",
      " global_average_pooling1d_1   (None, 256)              0         \n",
      " (GlobalAveragePooling1D)                                        \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 15,401,217\n",
      "Trainable params: 15,401,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 398/4018 [=>............................] - ETA: 4:48 - loss: -3984096512.0000 - sparse_categorical_accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m my_model\u001b[39m.\u001b[39;49mfit(train_tf_ds, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\Polar\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Polar\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Polar\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Polar\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Polar\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\Polar\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Polar\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Polar\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Polar\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_model.fit(train_tf_ds, verbose=1, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a4703bde01830f6d095c98ee537b927e3a42233672027169c1dba6e7efc366de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
